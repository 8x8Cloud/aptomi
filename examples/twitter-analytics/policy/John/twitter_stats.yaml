# Definition of Twitter Stats service
- kind: service
  metadata:
    namespace: social
    name: twitter_stats

  components:

    - name: analytics_pipeline
      contract: platform/analytics_pipeline

    # Publisher (Twitter Streaming API -> kafka)
    - name: tweepub
      code:
        type: helm
        params:
          chartRepo: https://mirantisworkloads.storage.googleapis.com
          chartName: "{{ .Labels.chart_name }}"

          # Pass labels to publisher application
          twitter:
            baseWord: "{{ default .Labels.base_word }}"
            appKey: "{{ default .Labels.appKey }}"
            appSecret: "{{ default .Labels.appSecret }}"
            tokenKey: "{{ default .Labels.tokenKey }}"
            tokenSecret: "{{ default .Labels.tokenSecret }}"
            locations: "{{ default .Labels.locations }}"

          # Tell publisher where to put messages (kafka connection url & topic)
          kafka:
            deployChart: false
            addresses:
              kafka: "{{ .Discovery.analytics_pipeline.kafka.kafka.url }}"
            topic: "tweepub-{{ .Discovery.Service.InstanceId }}"

      dependencies:
        - analytics_pipeline

    # Spark job (takes tweets -> does hashtags stats -> puts stats into hdfs)
    - name: tweetics
      code:
        type: helm
        params:
          chartRepo: https://mirantisworkloads.storage.googleapis.com
          chartName: tweetics

          zookeeper:
            addresses:
              zookeeper: "{{ .Discovery.analytics_pipeline.kafka.zookeeper.zookeeper.url }}"

          kafka:
            addresses:
              kafka:  "{{ .Discovery.analytics_pipeline.kafka.kafka.url }}"
            topic: "tweepub-{{ .Discovery.Service.InstanceId }}"

          spark:
            deployChart: false
            addresses:
              spark: "{{ .Discovery.analytics_pipeline.spark.spark.url }}"
            batchDuration: 5

          hdfs:
            addresses:
              namenode: "{{ .Discovery.analytics_pipeline.hdfs.hdfs.url }}"
            path: "/twitter-{{ .Discovery.Service.InstanceId }}/results"
      dependencies:
        - analytics_pipeline

    # Visualizer (takes stats from hdfs and shows on web page)
    - name: tweeviz
      code:
        type: helm
        params:
          chartRepo: https://mirantisworkloads.storage.googleapis.com
          chartName: tweeviz

          image:
            repository: aptomi/
            name: tweeviz
            tag: "v1.2.0-{{ .Labels.tsvisimage }}"

          topListSize: 10

          header: "Twitter Stats {{ .User.Name }} ({{ .Discovery.Instance }})"

          hdfs:
            addresses:
              namenode: "{{ .Discovery.analytics_pipeline.hdfs.hdfs.url }}"
            path: "/twitter-{{ .Discovery.Service.InstanceId }}"

      dependencies:
        - analytics_pipeline

# Contract for Twitter Stats
- kind: contract
  metadata:
    namespace: social
    name: twitter_stats

  contexts:
    # Twitter Stats implementation which receives twitter messages from Twitter Streaming API
    - name: realtime
      criteria:
        require-all:
          - org == 'it' && is_operator
      change-labels:
        set:
          service_realtime: true
          chart_name: tweepub
      allocation:
        service: twitter_stats

    # Twitter Stats implementation which generates a constant stream of fake twitter messages
    - name: fake
      criteria:
        require-all:
          - org == 'dev'
      change-labels:
        set:
          service_fake: true
          chart_name: tweepub-fake
          base_word: "development"
      allocation:
        service: twitter_stats
        keys:
          - "{{ .User.Name }}"
